{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "improting the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay , roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funtions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(X_train_scaled , y_train , PLOT = False , num_epochs = 80 , input_shape =12 , train = True):\n",
    "    # Build the neural network\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(256, activation='relu', input_shape=(input_shape,), kernel_regularizer=regularizers.l2(0.01)),\n",
    "        keras.layers.Dropout(0.4),  # Dropout layer with a 50% dropout rate\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.4),  # Dropout layer with a 50% dropout rate\n",
    "        keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(f'best_model_{num_epochs}.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    # Training\n",
    "    if train :\n",
    "        history = model.fit(X_train_scaled, y_train, epochs=num_epochs, batch_size=32, validation_split=0.2 ,  callbacks=[checkpoint])\n",
    "    else:\n",
    "        \n",
    "        return print((model.summary()))\n",
    "    if PLOT:\n",
    "        training_loss = history.history['loss']\n",
    "        training_accuracy = history.history['accuracy']\n",
    "        validation_loss = history.history['val_loss']\n",
    "        validation_accuracy = history.history['val_accuracy']\n",
    "\n",
    "        # Plot the training and validation loss\n",
    "        plt.plot(training_loss, label='Training Loss')\n",
    "        plt.plot(validation_loss, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the training and validation accuracy\n",
    "        plt.plot(training_accuracy, label='Training Accuracy')\n",
    "        plt.plot(validation_accuracy, label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "   \n",
    "    return model\n",
    "    \n",
    "\n",
    "def pca_trans(X_train , X_test , n_comp = 12):\n",
    "   \n",
    "    shape_1 = X_train.shape\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    pca = pca.fit(X_train)\n",
    "\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    shape_2 = X_train_pca.shape\n",
    "    print (f\"INPUT DATA SHAPE WAS {shape_1}  final shape = {shape_2}\")\n",
    "    return X_train_pca , X_test_pca\n",
    "def Scaler(new_data , ratio = 9000):\n",
    "    train_data = new_data[:ratio]\n",
    "    test_data = new_data[ratio:]\n",
    "    train_data_val = train_data.pop('Exited')\n",
    "    test_data_val = test_data.pop(\"Exited\")\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_data.to_numpy())\n",
    "    Y_train = train_data_val.to_numpy()\n",
    "    X_test_scaled = scaler.fit_transform(test_data.to_numpy())\n",
    "    Y_test = test_data_val.to_numpy()\n",
    "    return X_train_scaled , Y_train , X_test_scaled , Y_test\n",
    "\n",
    "\n",
    "def save( X_test_pca ,Y_test  ):\n",
    "# Reshape Y_test to have shape (1000, 1)\n",
    "    Y_test = Y_test.reshape(-1, 1)\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    df = pd.DataFrame(np.hstack((X_test_pca, Y_test)), columns=['Feature_{}'.format(i) for i in range(X_test_pca.shape[1])] + ['Y Value'])\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv('test_data.csv', index=False)\n",
    "\n",
    "\n",
    "def compute_metrics(y_pred ,Y_test , thresh ):\n",
    "    y_pred_binary = y_pred >= thresh\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, y_pred)\n",
    "\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})\n",
    "    ideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\n",
    "    print(\"Ideal threshold is: \", ideal_roc_thresh['thresholds']) \n",
    "\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    print(\"Area under curve, AUC = \", auc_value)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(Y_test, y_pred_binary)\n",
    "    print (cm)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "   \n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'y--')\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = input (\"Path to the data: \")\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode the columns\n",
    "full_data = data.copy()\n",
    "full_data = pd.get_dummies(full_data)\n",
    "\n",
    "## scla the data \n",
    "X_train , Y_train , X_test  , Y_test = Scaler(full_data)\n",
    "\n",
    "## dimensionality reduction\n",
    "\n",
    "X_train_pca , X_test_pca = pca_trans(X_train , X_test , n_comp = 12)\n",
    "\n",
    "\n",
    "## create the model \n",
    "model = neural_net(X_train_pca , Y_train , train = True , PLOT = True, num_epochs = 80 , input_shape = 12)\n",
    "\n",
    "\n",
    "## evaluating  the model \n",
    "\n",
    "_, acc = model.evaluate(X_test_pca, Y_test)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction \n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_pred)\n",
    "\n",
    "i = np.arange(len(tpr)) \n",
    "roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'thresholds' : pd.Series(thresholds, index=i)})\n",
    "ideal_roc_thresh = roc.iloc[(roc.tf-0).abs().argsort()[:1]]  #Locate the point where the value is close to 0\n",
    "print(\"Ideal threshold is: \", ideal_roc_thresh['thresholds']) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mythreshold=    float(input(\"Enter the thresh hold: \"))\n",
    "compute_metrics(y_pred , Y_test , mythreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
